# Reality Synthesizer: Visualize MIDI Notes in Augmented Reality
iOS 15.4 opened up the LiDAR sensor to AVFoundation. In this demo MIDI notes played on
a paired synthesizer are interpreted by Metal shaders to produce augmented reality visualizations. This demo builds on parts of
[Capturing Depth Using the LiDAR Camera](https://developer.apple.com/documentation/avfoundation/cameras_and_media_capture/capturing_depth_using_the_lidar_camera), 
[AudioKit](https://github.com/AudioKit/AudioKit), and [Linnstrument Helper](https://github.com/markjamesm/linnstrument-helper). 

![Reality Synthesizer Demo Gif](https://github.com/robomex/Reality-Synthesizer/blob/main/Reality-Synthesizer-Demo.gif)
